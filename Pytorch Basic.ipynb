{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch 기초 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = torch.arange(9)\n",
    "nums.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums.reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = torch.arange(9).reshape(3, 3)\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  2,  4],\n",
       "        [ 6,  8, 10],\n",
       "        [12, 14, 16]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num + num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서의 생성과 변환\n",
    "- 텐서는 파이토치의 가장 기본이 되는 데이터 구조와 기능을 제공하는 다차원 배열을 처리하기 위한 데이터 구조 입니다.\n",
    "- API 형태는 `Numpy`의 ndarray와 비슷하며 GPU를 사용하는 계산도 지원한다.\n",
    "- 텐서는 각 데이터 형태별러 정의되어 있다.\n",
    "    - `torch.FloatTensor` : 32-bit float point\n",
    "    - `torch.LongTensor` : 64-bit signed integer\n",
    "- GPU상에서 계산을 할때는 torch.cuda.FloatTensor을 사용한다. 일반적으로 Tensor는 FloatTensor라고 생각하면 된다.\n",
    "- 어떤 형태의 텐서에 상관없이 torch.tensor라는 함수로 작성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2차원 형태의 list를 만들어서 텐서 생성\n",
    "torch.tensor([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device를 지정하여 GPU에 텐서를 만듬\n",
    "torch.tensor([[1, 2], [3, 4.]], device = \"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype을 이용하여 텐서의 데이터 형태 지정가능\n",
    "torch.tensor([[1, 2], [3, 4.]], dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arange를 이용한 1차원 텐서\n",
    "torch.arange(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 값이 0인 3 * 5의 텐서를 작성하여 to메소드를 사용해 GPU에 전송\n",
    "torch.zeros(3, 5).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7060,  0.9628,  0.3808, -2.2241, -0.2123],\n",
       "        [-0.1785, -1.2674,  0.2534,  0.1733,  1.2188],\n",
       "        [-2.3550, -0.9656, -1.5710,  1.4030, -0.3438]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normal distribution으로 행렬 생성\n",
    "torch.randn(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor의 shape은 size()로 확인\n",
    "t = torch.randn(3, 5)\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서는 Numpy의 ndarray로 쉽게 변환가능\n",
    "- 주의!!!!!, GPU상의 텐서는 그대로 변환할 수 없으며, CPU로 이동후 변환해야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# numpy를 사용해 ndarray로 변환\n",
    "t = torch.tensor([[1, 2], [3, 4.]])\n",
    "print(type(t))\n",
    "\n",
    "x = t.numpy()\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], device='cuda:0') <class 'torch.Tensor'>\n",
      "[[1. 2.]\n",
      " [3. 4.]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# GPU 상의 텐서의 경우 to()로 CPU상의 텐서로 변환한 뒤 ndarray로 변환해야 한다.\n",
    "t = torch.tensor([[1, 2], [3, 4.]], device=\"cuda:0\")\n",
    "print(t, type(t))\n",
    "\n",
    "x = t.to(\"cpu\").numpy()\n",
    "print(x, type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.linspace(start, end, step)` : 시작과 끝을 포함하고 step의 개수만큼 원소를 가진 등차수열을 생성함\n",
    "- torch에서 바로 이런 값들을 만들면 torch 내부적으로도 사용할 수 있지만 numpy와 호환되는 라이브러리에도 사용가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f97f0f92130>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.linspace(0, 10, 5)\n",
    "y = torch.exp(x)\n",
    "\n",
    "plt.plot(x.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor의 인덱스 조작\n",
    "- 인덱스의 경우 Numpy와 같이 조작하는 것이 가능하다. 배열처럼 인덱스를 바로 지정 가능하고 슬라이스, 마스크 배열을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor([[1, 2],\n",
      "        [4, 5]])\n",
      "tensor([4, 5, 6])\n",
      "tensor([[ 1, 10,  3],\n",
      "        [ 4, 10,  6]])\n",
      "tensor([[ 1, 20,  3],\n",
      "        [ 4, 20, 20]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([\n",
    "    [1, 2, 3], [4, 5, 6]\n",
    "])\n",
    "# index 접근\n",
    "print(t[0, 2])\n",
    "# slice로 접근 \n",
    "print(t[:, :2])\n",
    "# 마스크 배열을 이용해 True값만 추출\n",
    "print(t[t > 3])\n",
    "# 슬라이스를 이용해 일괄 대입\n",
    "t[:, 1] = 10\n",
    "print(t)\n",
    "# 마스크 배열을 사용해 일괄 대입\n",
    "t[t > 5] = 20\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Operation\n",
    "- Tensor는 Numpy의 ndarray와 같이 다양한 수학 연산이 가능하며 GPU를 사용할 시 더 빠른 연산이 가능하다.\n",
    "- 텐서에서의 사칙연산은 같은 타입의 텐서 간 또는 텐서와 파이썬의 스칼라 값 사이에서만 가능하다.\n",
    "    - 타입이 다르면 텐서간의 연산이어도 연산이 되지 안는다. FloatTensor, DoubleTensor간의 사칙 연산은 오류가 발생한다\n",
    "- 스칼라 값을 연산할 때는 기본적으로 `Broadcasting`이 적용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11., 12., 13.])\n",
      "tensor([1., 4., 9.])\n",
      "tensor([  1.,  -8., -17.])\n",
      "tensor([ 8.,  9., 10.])\n",
      "tensor([[  0.,   2.,   4.],\n",
      "        [200., 400., 600.]])\n",
      "tensor([[  1.,   3.,   5.],\n",
      "        [101., 202., 303.]])\n",
      "tensor([[  0.,   2.,   4.],\n",
      "        [200., 400., 600.]])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([1, 2, 3.])\n",
    "w = torch.tensor([0, 10, 20])\n",
    "\n",
    "m = torch.tensor([\n",
    "    [0, 1, 2], [100, 200, 300.]\n",
    "])\n",
    "\n",
    "v2 = v + 10\n",
    "print(v2)\n",
    "\n",
    "v2 = v ** 2\n",
    "print(v2)\n",
    "\n",
    "z = v - w\n",
    "print(z)\n",
    "\n",
    "u = 2 * v - w / 10 + 6.0\n",
    "print(u)\n",
    "\n",
    "m2 = m * 2.0 # 행렬과 스칼라의 곱\n",
    "print(m2)\n",
    "\n",
    "print(m + v)\n",
    "\n",
    "print(m + m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서의 차원 조작\n",
    "- 텐서의 차원을 변경하는 `view`나 텐서를 결합하는 `stack`, `cat`, 차원을 교환하는 `t', `transpose`도 사용 가능\n",
    "- view의 경우 reshape과 동일한 역할 (추천 : reshape)\n",
    "- cat의 경우 다른 길이의 텐서를 하나로 묶을 때 사용됨\n",
    "- transpose의 경우 행렬의 전치 외에도 차원의 순서를 변경할 때 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([[1, 2, 3, 4]])\n",
      "tensor([[1, 2, 3, 4]])\n",
      "tensor([[10., 40.],\n",
      "        [20., 50.],\n",
      "        [30., 60.]])\n",
      "tensor([[ 1.,  2., 10., 20., 30.],\n",
      "        [ 3.,  4., 40., 50., 60.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 64, 32])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor([\n",
    "    [1, 2], [3, 4]\n",
    "])\n",
    "x2 = torch.tensor([\n",
    "    [10, 20, 30], [40, 50, 60.]\n",
    "])\n",
    "\n",
    "print(x1.view(4, 1))\n",
    "\n",
    "print(x1.reshape(4, 1))\n",
    "\n",
    "print(x1.view(-1)) # 1차원 벡터로 변형\n",
    "\n",
    "print(x1.reshape(-1))\n",
    "\n",
    "print(x1.view(1, -1)) # -1을 사용하면 자동 계산함\n",
    "\n",
    "print(x1.reshape(1, -1))\n",
    "\n",
    "print(x2.t())\n",
    "\n",
    "print(torch.cat([x1, x2], dim=1))\n",
    "\n",
    "# transpose(dim1, dim2)을 사용하면 dim1의 차원과 dim2의 차원을 교환한다.\n",
    "hwc_img_data = torch.rand(100, 64, 32, 3)\n",
    "chw_img_data = hwc_img_data.transpose(1, 2).transpose(1, 3)\n",
    "# 첫번째 transpose : (100, 32, 64, 3)\n",
    "# 두번째 transpose : (100, 3, 64, 32)\n",
    "chw_img_data.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor 생성\n",
    "- Tensor를 생성할 때 대표적으로 사용하는 함수가 `rand, zeros, ones`이다. 이 때 첫 인자는 dimension이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0778, 0.4926, 0.7533],\n",
      "        [0.6035, 0.5240, 0.7936]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 0, 5, 2, 4])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 순열 생성\n",
    "torch.torch.randperm(6) # 0과 n사이 값으로 n개의 순열을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(2, 3)\n",
    "print(zeros)\n",
    "torch.zeros_like(zeros) # zeros_like and ones_like의 경우 인자로 받은 데이터의 크기와 똑같이 0 혹은 1로 채워진 값을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.ones(2, 3))\n",
    "\n",
    "ones = torch.randn(3, 4)\n",
    "torch.ones_like(ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- arange를 이용한 Tensor 생성\n",
    "- `torch.arange(start, end, step)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 3, step=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor 데이터 타입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2행 3열의 Float 타입의 Tensor 생성\n",
    "torch.cuda.FloatTensor(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리스트를 입력해서 특정 리스트를 Tensor로 변환하기\n",
    "torch.cuda.FloatTensor([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float type을 int type으로 형 변환\n",
    "x = torch.cuda.FloatTensor([2, 3])\n",
    "x.type_as(torch.cuda.IntTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3.], device='cuda:0')\n",
      "tensor([2., 3.])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.FloatTensor([2, 3])) # GPU Tensor\n",
    "print(torch.FloatTensor([2, 3])) # CPU Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy to Tensor or Tensor to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.ndarray(shape=(2, 3), dtype = int, buffer=np.array([1, 2, 3, 4, 5, 6]))\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.from_numpy(x1)\n",
    "x2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU type과 GPU type의 Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2, 3], [4, 5, 6]])\n",
    "x_gpu = x.cuda()\n",
    "x_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cpu = x_gpu.cpu()\n",
    "x_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index (slicing) 기능 사용방법\n",
    "- 배열, 행렬에서 인덱스 기능을 사용해서 특정 값들을 조회하는 것처럼 Tensor에서도 조회가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1455, 0.5188, 0.0552],\n",
      "        [0.6757, 0.4141, 0.8950],\n",
      "        [0.7604, 0.7204, 0.5343],\n",
      "        [0.7160, 0.9575, 0.3473]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1455, 0.5188, 0.0552],\n",
       "        [0.7604, 0.7204, 0.5343]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4, 3)\n",
    "print(x)\n",
    "# torch.index_select(input, dim, index) ==> input 값에서 dim차원을 기준으로 index에 전달 된 값을 indexing or slicing한다\n",
    "torch.index_select(x, 0, torch.LongTensor([0, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.masked_select(input, mask)` 함수를 이용하여 선택할 영역에는 1을 미선택할 영역은 0을 입력 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6955, -2.9846, -0.0350],\n",
      "        [ 0.4091, -0.7817, -0.3029]])\n",
      "tensor([[False, False,  True],\n",
      "        [False,  True, False]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0350, -0.7817])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3)\n",
    "print(x)\n",
    "\n",
    "# mask는 0,1 값을 가지고 ByteTensor를 이용하여 생성합니다.\n",
    "# (0,3)과 (1,1) 데이터 인덱싱\n",
    "mask = torch.BoolTensor([[0,0,1],[0,1,0]]) # ByteTensor는 사라졌으므로 BoolTensor를 사용함\n",
    "print(mask)\n",
    "torch.masked_select(x,mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join (cat, stack) 기능 사용 방법\n",
    "- PyTorch에서 torch.cat(seq, dim)을 이용하여 concaternate 연산을 할 수 있습니다.\n",
    "- dim은 concaternate할 방향을 정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [-1., -2., -3.],\n",
      "        [-4., -5., -6.]], device='cuda:0')\n",
      "tensor([[ 1.,  2.,  3., -1., -2., -3.],\n",
      "        [ 4.,  5.,  6., -4., -5., -6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.cuda.FloatTensor([[1, 2, 3], [4, 5, 6]])\n",
    "y = torch.cuda.FloatTensor([[-1, -2, -3], [-4, -5, -6]])\n",
    "z1 = torch.cat([x, y], dim=0)\n",
    "print(z1)\n",
    "z2 = torch.cat([x, y], dim=1)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [3., 4., 5.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [3., 4., 5.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [3., 4., 5.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [3., 4., 5.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2, 3], [3, 4, 5]])\n",
    "x_stack = torch.stack([x, x, x, x], dim=0)\n",
    "x_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing 기능 사용방법\n",
    "- slicing 기능은 Tensor를 몇 개의 부분으로 나뉘는 기능이다.\n",
    "- `torch.chunk(tensor, chunks, dim=0)`, `torch.split(tensor, split_size, dim=0)`함수를 이용하여 Tensor를 나눌 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [-1., -2., -3.],\n",
      "        [-4., -5., -6.]], device='cuda:0')\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0')\n",
      "tensor([[-1., -2., -3.],\n",
      "        [-4., -5., -6.]], device='cuda:0')\n",
      "tensor([[ 1.],\n",
      "        [ 4.],\n",
      "        [-1.],\n",
      "        [-4.]], device='cuda:0')\n",
      "tensor([[ 2.],\n",
      "        [ 5.],\n",
      "        [-2.],\n",
      "        [-5.]], device='cuda:0')\n",
      "tensor([[ 3.],\n",
      "        [ 6.],\n",
      "        [-3.],\n",
      "        [-6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x1, x2 = torch.chunk(z1, 2, dim=0)\n",
    "y1, y2, y3 = torch.chunk(z1, 3, dim=1)\n",
    "\n",
    "print(z1)\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeezing 기능 사용 방법\n",
    "- squeeze 함수를 사용하면 dimension중 1인 것을 압축할 수 있습니다.\n",
    "- torch.squeeze(input, dim) 으로만 사용할 수 있고, dim을 지정하지 않으면 dimension이 1인 것을 모두 압축하고 지정하면 지정한 dimension만 압축한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2, 1, 2])\n",
      "torch.Size([2, 2, 2])\n",
      "torch.Size([2, 1, 2, 1, 2])\n",
      "torch.Size([2, 2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2, 1, 2, 1, 2)\n",
    "print(x.size())\n",
    "\n",
    "y = torch.squeeze(x) # dimension이 1인 것 모두 압축\n",
    "print(y.size())\n",
    "\n",
    "y = torch.squeeze(x, 0) # 차원이 0인 부분의 dimension이 1이면 입축 아니면 압축안함\n",
    "print(y.size())\n",
    "\n",
    "y = torch.squeeze(x, 1) # 차원이 1인 부분의 dimension이 1이면 압축 아니면 압축 안함\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- unsqueeze함수를 사용하면 dimension을 추가할 수 있다. \n",
    "- unsqueeze 함수는 dimension을 반드시 입력받게 되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([1, 2, 3, 4])\n",
      "torch.Size([4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2, 3, 4)\n",
    "print(x.size())\n",
    "print(torch.unsqueeze(x, 0).size())\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(x.size())\n",
    "print(torch.unsqueeze(x, 0).size())\n",
    "print(torch.unsqueeze(x, 1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization 방법\n",
    "- `init.uniform`함수를 사용하면 uniform or normal 분포의 초기화 Tensor를 만들수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0108, 3.0686, 0.5821, 8.2017],\n",
      "        [2.2282, 5.1180, 7.2596, 4.1994],\n",
      "        [8.1196, 2.6053, 2.8803, 1.7376]])\n"
     ]
    }
   ],
   "source": [
    "x1 = init.uniform_(torch.FloatTensor(3, 4), a=0, b=9) # 이는 (a, b) 구간 내에서 균일분포 행렬을 생성\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0543, -0.2132, -0.2203, -0.2802],\n",
      "        [-0.0809, -0.1554,  0.2126, -0.1900],\n",
      "        [-0.2851,  0.0640, -0.0369,  0.1408]])\n"
     ]
    }
   ],
   "source": [
    "x2 = init.normal_(torch.FloatTensor(3, 4), std=0.2) # 표준편차가 0.2가 되도록 생성, mean 인자의 경우 mean인자 만큼의 평균으로 생성\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1415, 3.1415, 3.1415, 3.1415],\n",
      "        [3.1415, 3.1415, 3.1415, 3.1415],\n",
      "        [3.1415, 3.1415, 3.1415, 3.1415]])\n"
     ]
    }
   ],
   "source": [
    "x3 = init.constant_(torch.FloatTensor(3, 4), 3.1415)\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math operation\n",
    "- `dot` : 벡터 내적\n",
    "- `mv` : 행렬과 벡터의 곱\n",
    "- `mm` : 행렬과 행렬의 곱\n",
    "- `matmul` : 인수의 종류에 따라서 자동으로 dot, mv, mm선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[9, 8, 7],\n",
      "        [6, 5, 4]])\n",
      "tensor([[21, 18, 15],\n",
      "        [51, 44, 37],\n",
      "        [81, 70, 59]])\n",
      "tensor([[21, 18, 15],\n",
      "        [51, 44, 37],\n",
      "        [81, 70, 59]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3, 4, 5, 6]).reshape(3, 2)\n",
    "b = torch.tensor([9, 8, 7, 6, 5, 4]).reshape(2, 3)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "ab = torch.matmul(a, b)\n",
    "print(ab)\n",
    "ab = a@b\n",
    "print(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n",
      "==================================\n",
      "torch.Size([10, 3, 5])\n",
      "==================================\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2])\n",
      "==================================\n",
      "torch.Size([10, 3, 4, 5])\n",
      "torch.Size([10, 4, 3, 5])\n",
      "torch.Size([10, 3, 5, 4])\n",
      "==================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.eig(\n",
       "eigenvalues=tensor([[-1.2130e-08,  2.1010e-08],\n",
       "        [-1.2130e-08, -2.1010e-08],\n",
       "        [ 2.4261e-08,  0.0000e+00],\n",
       "        [ 4.9873e-18,  0.0000e+00]]),\n",
       "eigenvectors=tensor([[-4.7593e-10,  8.2435e-10, -9.5186e-10,  3.4925e-10],\n",
       "        [-1.0000e+00,  0.0000e+00,  1.0000e+00, -1.0000e+00],\n",
       "        [ 7.4581e-22,  3.8774e-27, -7.4581e-22,  9.7656e-04],\n",
       "        [ 6.2247e-15,  1.0781e-14,  1.2449e-14,  6.0797e-08]]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add operation torch.add(a, b) or + 이는 Broadcasting을 수행\n",
    "# mul operation torch.mul(a, b) or * 이는 Broadcasting을 수행\n",
    "# div operation torch.div(a, b) or / 이는 Broadcasting을 수행\n",
    "# pow operation torch.pow(input, exponent) or **\n",
    "# exponential operation torch.exp(tensor, out=None)\n",
    "# log operation torch.log(input, out=None) -> natural logarithm\n",
    "# matrix mul operation torch.mm(mat1, mat2)\n",
    "x1 = torch.FloatTensor(3, 4)\n",
    "x2 = torch.FloatTensor(4, 5)\n",
    "print(torch.mm(x1, x2).size())\n",
    "print('==================================')\n",
    "# torch.bmm(batch1, batch2) -> batch matrix multiplication\n",
    "# 이는 Tensor의 곱을 batch단위로 수행한다. \n",
    "x1 = torch.FloatTensor(10, 3, 4)\n",
    "x2 = torch.FloatTensor(10, 4, 5)\n",
    "print(torch.bmm(x1, x2).size())\n",
    "print('==================================')\n",
    "# dot operation torch.dot(tensor1, tensor2)\n",
    "# transpose operation torch.t()\n",
    "x1 = torch.FloatTensor(2, 3)\n",
    "x2 = x1.t()\n",
    "print(x1.size())\n",
    "print(x2.size())\n",
    "print('==================================')\n",
    "# 특정 dimension transpose operation torch.transpose()\n",
    "x1 = torch.FloatTensor(10 ,3, 4, 5)\n",
    "print(x1.size())\n",
    "print(torch.transpose(x1, 1, 2).size())\n",
    "print(torch.transpose(x1, 2, 3).size())\n",
    "print('==================================')\n",
    "# eigenvalue, eigenvector를 구하는 방법\n",
    "x1 = torch.FloatTensor(4, 4)\n",
    "torch.eig(x1, eigenvectors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd 사용 방법\n",
    "- 어떤 tensor가 학습에 필요한 tensor라면 backpropagation을 통해 gradient를 구해야 한다.\n",
    "- tensor의 gradient를 구하기 위해서는 다음의 조건들을 만족하야 한다.\n",
    "    - Tensor의 옵션이 `requires_grad=True`로 설정되어야 한다. (default : requires_grad=False)\n",
    "    - backpropagation을 시작할 지점의 output은 scalar형태여야 한다.\n",
    "- tensor의 gradient를 구하는 방법은 backpropagation을 시작할 지점의 tensor에서 `.backward()` 함수를 호출하면 끝\n",
    "- gradient의 값을 확인하기 위해서는 requires_grad=True로 설정한 tensor에서 `.grad()`를 통해 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(330.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = 9*x**4 + 2*x**3 + 3*x**2 + 6*x + 1\n",
    "y.backward() # 주의!!!!!! y의 값이 scalar여야 계산이 가능\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n",
      "tensor([[3., 4.],\n",
      "        [5., 6.]], grad_fn=<AddBackward0>)\n",
      "tensor([[4.5000, 6.0000],\n",
      "        [7.5000, 9.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1.0, 2.0],[3.0, 4.0]], requires_grad = True)\n",
    "print(x)\n",
    "# tensor([[1., 2.],\n",
    "#         [3., 4.]], requires_grad=True)\n",
    "\n",
    "y = x + 2\n",
    "print(y)\n",
    "# tensor([[3., 4.],\n",
    "#         [5., 6.]], grad_fn=<AddBackward0>)\n",
    "\n",
    "z = y * y * 3\n",
    "# tensor([[ 27.,  48.],\n",
    "#         [ 75., 108.]], grad_fn=<MulBackward0>)\n",
    "\n",
    "out = z.mean()\n",
    "# tensor(64.5000, grad_fn=<MeanBackward0>)\n",
    "\n",
    "out.backward()\n",
    "print(x.grad)\n",
    "# tensor([[4.5000, 6.0000],\n",
    "#         [7.5000, 9.0000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- partial derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.) tensor(12.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "z = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**2 + z**3\n",
    "\n",
    "y.backward()\n",
    "print(x.grad, z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 모드와 평가 모드\n",
    "- 앞에서는 gradient를 구하기 위해 tensor의 속성을 변경하였다. 즉 gradient를 구한다는 것은 학습 대상이 되는 weight라는 뜻이다.\n",
    "- 그런데 학습이 끝난 이후 평가를 하는 과정에서는 굳이 학습 모드로 사용할 필요가 없다.\n",
    "- 이때 사용하는 것이 torch.no_grad()이다. torch.no_grad()가 적용된 tensor는 실제 속성은 requiers_grad=True지만 gradient를 업데이트 하기 않고, dropout, batchnormalization을 적용하기 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "print(x.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(x.requires_grad)\n",
    "    print((x**2).requires_grad)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
