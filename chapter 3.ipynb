{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 역진자 태스크 \"CartPole\"\n",
    "- 역진자 태스크란 수레 위에 회전축을 고정한 봉을 세워두고, 수레를 좌우로 움직이며 이 봉이 쓰러지지 않도록 제어하는 과제를 말한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 애니메이션을 만드는 함수\n",
    "# 참고 URL http://nbviewer.jupyter.org/github/patrickmineault/xcorr-notebooks/blob/master/Render%20OpenAI%20gym%20as%20GIF.ipynb\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(frames[0].shape[1]/72.0, frames[0].shape[0]/72.0),\n",
    "               dpi=72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames=len(frames),\n",
    "                                   interval=50)\n",
    "\n",
    "    #anim.save('movie_cartpole.mp4')  # 주석 추가 : 애니메이션을 저장하는 부분\n",
    "    display(display_animation(anim, default_mode='loop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/Pytorch/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "# 수레를 무작위로 움직임\n",
    "\n",
    "frames = []\n",
    "env = gym.make('CartPole-v0')\n",
    "observation = env.reset()  # 먼저 환경을 초기화해야 함\n",
    "\n",
    "for step in range(0, 200):\n",
    "    frames.append(env.render(mode='rgb_array'))  # frames에 각 시각의 이미지를 추가한다\n",
    "    action = np.random.choice(2)  # 0(수레를 왼쪽으로), 1(수레를 오른쪽으로) 두 가지 행동을 무작위로 취함\n",
    "    \n",
    "    # observation은 수레와 봉의 상태를 나타낸다. reward의 경우 즉각보상을 의미, done은 게임의 종료여부를 나타냄, info의 경우 디버깅 등에 필요한 정보를 담은 변수이다.\n",
    "    observation, reward, done, info = env.step(action)  # action을 실행 (이는 총 4개의 값을 반환한다)\n",
    "\n",
    "# 주의: 실행했을 때 ipykernel_launcher.p... 라는 창이 나타날 수 있지만, 무시하면 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다변수 연속 값을 이산변수로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구현에 사용할 패키지 임포트\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상수 정의\n",
    "ENV = 'CartPole-v0'  # 태스크 이름\n",
    "NUM_DIZITIZED = 6  # 각 상태를 이산변수로 변환할 구간 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CartPole 실행\n",
    "env = gym.make(ENV)  # 태스크 실행 환경 생성\n",
    "observation = env.reset()  # 환경 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이산변수 변환에 사용할 구간을 계산\n",
    "def bins(clip_min, clip_max, num):\n",
    "    '''관측된 상태(연속값)을 이산값으로 변환하는 구간을 계산'''\n",
    "    return np.linspace(clip_min, clip_max, num + 1)[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.4, -1.6, -0.8,  0. ,  0.8,  1.6,  2.4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(-2.4, 2.4, 6 + 1) # linspace는 나눌 구간의 수를 인자로 받아 해당 데이터의 범위를 구간 수에 맞게 나누어주는 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6, -0.8,  0. ,  0.8,  1.6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(-2.4, 2.4, 6 + 1)[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digitize_state(observation):\n",
    "    '''관측된 상태(observation)을 이산값으로 변환'''\n",
    "    cart_pos, cart_v, pole_angle, pole_v = observation\n",
    "    # dititize함수의 경우 bins 인자를 통해 연속된 값을 구간의 수로 나누었을 때 인자로 받은 값이 어느 범위의 이산 변수값을 확인하여 이산변수를 반환해주는 함수이다.\n",
    "    digitized = [\n",
    "        np.digitize(cart_pos, bins=bins(-2.4, 2.4, NUM_DIZITIZED)), # cart_pos가 bins인자로 받은 구간에서 어디에 속하는지를 이산 값으로 반환 \n",
    "        np.digitize(cart_v, bins=bins(-3.0, 3.0, NUM_DIZITIZED)),  # cart_v 가 bins인자로 받은 구간에서 어디에 속하는지를 이산 값으로 반환\n",
    "        np.digitize(pole_angle, bins=bins(-0.5, 0.5, NUM_DIZITIZED)), # pole_angle 가 bins인자로 받은 구간에서 어디에 속하는지를 이산 값으로 반환\n",
    "        np.digitize(pole_v, bins=bins(-2.0, 2.0, NUM_DIZITIZED))] # pole_v 가 bins인자로 받은 구간에서 어디에 속하는지를 이산 값으로 반환\n",
    "    return sum([x * (NUM_DIZITIZED**i) for i, x in enumerate(digitized)]) # NUM_DIGITIZE진수로 변환하여 값을 반환함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitize_state(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning을 사용한 CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구현에 사용할 패키지 임포트\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 애니메이션을 만드는 함수\n",
    "# 참고 URL http://nbviewer.jupyter.org/github/patrickmineault\n",
    "# /xcorr-notebooks/blob/master/Render%20OpenAI%20gym%20as%20GIF.ipynb\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(frames[0].shape[1]/72.0, frames[0].shape[0]/72.0),\n",
    "               dpi=72)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames=len(frames),\n",
    "                                   interval=50)\n",
    "\n",
    "    # anim.save('movie_cartpole.mp4')  # 애니메이션을 저장하는 부분\n",
    "    display(display_animation(anim, default_mode='loop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상수 정의\n",
    "ENV = 'CartPole-v0'  # 태스크 이름\n",
    "NUM_DIGITIZED = 8  # 각 상태를 이산변수로 변환할 구간 수\n",
    "GAMMA = 0.99  # 시간할인율\n",
    "ETA = 0.7  # 학습률\n",
    "MAX_STEPS = 200  # 1에피소드 당 최대 단계 수\n",
    "NUM_EPISODES = 1000  # 최대 에피소드 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    '''CartPole 에이전트 역할을 할 클래스, 봉 달린 수레다.'''\n",
    "    def __init__(self, num_states, num_actions):\n",
    "        self.brain = Brain(num_states, num_actions) \n",
    "        \n",
    "    def update_Q_function(self, observation, action, reward, observation_next): # Q함수 수정\n",
    "        self.brain.update_Q_table(observation, action, reward, observation_next)\n",
    "        \n",
    "    def get_action(self, observation, step): # 행동결정\n",
    "        action = self.brain.decide_action(observation, step)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain:\n",
    "    '''Agent의 두뇌 역할을 하는 클래스, Q러닝을 실제 수행'''\n",
    "    def __init__(self, num_states, num_actions):\n",
    "        self.num_actions = num_actions\n",
    "        # Create Q table\n",
    "        self.q_table = np.random.uniform(low=0, high=1, size=(NUM_DIGITIZED**num_states, num_actions))\n",
    "        \n",
    "    def bins(self, clip_min, clip_max, num):\n",
    "        return np.linspace(clip_min, clip_max, num+1)[1:-1] # 연속값을 이산 변수로 변환하는 구간을 계산\n",
    "    \n",
    "    def digitize_state(self, observation):\n",
    "        cart_pos, cart_v, pole_angle, pole_v = observation # the shape of observation : (1, 4)\n",
    "        digitized = [\n",
    "            np.digitize(cart_pos, self.bins(-2.4, 2.4, NUM_DIGITIZED)),\n",
    "            np.digitize(cart_v, self.bins(-3.0, 3.0, NUM_DIGITIZED)),\n",
    "            np.digitize(pole_angle, self.bins(-0.5, 0.5, NUM_DIGITIZED)),\n",
    "            np.digitize(pole_v, self.bins(-2.0, 2.0, NUM_DIGITIZED))\n",
    "        ]\n",
    "        return sum([x * (NUM_DIGITIZED**i) for i, x in enumerate(digitized)])\n",
    "    \n",
    "    def update_Q_table(self, observation, action, reward, observation_next):\n",
    "        state = self.digitize_state(observation) # 현재 관찰 값에 대한 상태를 구함\n",
    "        state_next = self.digitize_state(observation_next) # 다음 관찰 값에 대한 상태를 구함\n",
    "        \n",
    "        Max_Q_next = max(self.q_table[state_next][:]) # 최댓 값을 구함\n",
    "        # 최댓값을 사용해서 q_table을 수정함\n",
    "        self.q_table[state, action] = self.q_table[state, action] + ETA * (reward + GAMMA * Max_Q_next - self.q_table[state, action])\n",
    "        \n",
    "    def decide_action(self, observation, episode):\n",
    "        '''epsilon-greedy 알고리즘을 적용해 서서히 최적 행동의 비중을 늘림'''\n",
    "        state = self.digitize_state(observation)\n",
    "        epsilon = 0.5 * (1 / (episode + 1)) # episode를 실행할수록 최적 행동의 비중을 늘림\n",
    "        \n",
    "        if epsilon <= np.random.uniform(0, 1):\n",
    "            action = np.argmax(self.q_table[state][:])\n",
    "        else:\n",
    "            action = np.random.choice(self.num_actions)\n",
    "        return int(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    '''CartPole을 실행하는 환경역할을 하는 클래스'''\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(ENV)\n",
    "        num_states = self.env.observation_space.shape[0] # 태스크의 상태 변수 수를 구함\n",
    "        num_actions = self.env.action_space.n # 가능한 행동 수를 구함\n",
    "        self.agent = Agent(num_states, num_actions)\n",
    "        \n",
    "    def run(self):\n",
    "        complete_episode = 0 # 195단계 이상 버틴 에피소드 수\n",
    "        is_episode_final = False # 마지막 에피소드 여부\n",
    "        frames = []\n",
    "        \n",
    "        for episode in range(NUM_EPISODES):\n",
    "            observation = self.env.reset()\n",
    "            for step in range(MAX_STEPS):\n",
    "                if is_episode_final is True:\n",
    "                    frames.append(self.env.render(mode='rgb_array'))\n",
    "                \n",
    "                # 여기서 step인자로 episode를 선택한 이유는 epsilon-greedy알고리즘을 학습할때 episode가 진행될 때마다 epsilon을 줄이기 위함\n",
    "                action = self.agent.get_action(observation, episode) # Select action\n",
    "                observation_next, _, done, _ = self.env.step(action) # Calculate next state and next action\n",
    "                \n",
    "                if done:\n",
    "                    if step < 195:\n",
    "                        reward = -1 # 봉이 쓰러지면 페널티로 보상 -1을 부여\n",
    "                        complete_episode = 0\n",
    "                    else:\n",
    "                        reward = 1 # 성공시 보상으로 1을 주어줌\n",
    "                        complete_episode += 1 # 연속된 성공 기록을 업데이트\n",
    "                else:\n",
    "                    reward = 0 # episode가 진행되는 동안은 보상이 없다.\n",
    "                \n",
    "                # observation_next를 사용해 Q함수를 수정\n",
    "                self.agent.update_Q_function(observation, action, reward, observation_next)\n",
    "                # 다음 단계 상태 관측\n",
    "                observation = observation_next\n",
    "                \n",
    "                if done:\n",
    "                    print(f\"{episode} Episode : Fidished after {(step + 1)} time steps\")\n",
    "                    break\n",
    "                    \n",
    "            if is_episode_final is True:\n",
    "                break\n",
    "            \n",
    "            if complete_episode >= 10:\n",
    "                print(\"10 episode 연속 성공\")\n",
    "                is_episode_final = True # 다음 에피소드가 마지막 에피소드가 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Episode : Fidished after 10 time steps\n",
      "1 Episode : Fidished after 51 time steps\n",
      "2 Episode : Fidished after 16 time steps\n",
      "3 Episode : Fidished after 33 time steps\n",
      "4 Episode : Fidished after 16 time steps\n",
      "5 Episode : Fidished after 10 time steps\n",
      "6 Episode : Fidished after 19 time steps\n",
      "7 Episode : Fidished after 12 time steps\n",
      "8 Episode : Fidished after 11 time steps\n",
      "9 Episode : Fidished after 10 time steps\n",
      "10 Episode : Fidished after 23 time steps\n",
      "11 Episode : Fidished after 22 time steps\n",
      "12 Episode : Fidished after 29 time steps\n",
      "13 Episode : Fidished after 13 time steps\n",
      "14 Episode : Fidished after 49 time steps\n",
      "15 Episode : Fidished after 31 time steps\n",
      "16 Episode : Fidished after 88 time steps\n",
      "17 Episode : Fidished after 90 time steps\n",
      "18 Episode : Fidished after 115 time steps\n",
      "19 Episode : Fidished after 39 time steps\n",
      "20 Episode : Fidished after 51 time steps\n",
      "21 Episode : Fidished after 111 time steps\n",
      "22 Episode : Fidished after 39 time steps\n",
      "23 Episode : Fidished after 19 time steps\n",
      "24 Episode : Fidished after 25 time steps\n",
      "25 Episode : Fidished after 55 time steps\n",
      "26 Episode : Fidished after 21 time steps\n",
      "27 Episode : Fidished after 42 time steps\n",
      "28 Episode : Fidished after 86 time steps\n",
      "29 Episode : Fidished after 67 time steps\n",
      "30 Episode : Fidished after 36 time steps\n",
      "31 Episode : Fidished after 24 time steps\n",
      "32 Episode : Fidished after 32 time steps\n",
      "33 Episode : Fidished after 43 time steps\n",
      "34 Episode : Fidished after 51 time steps\n",
      "35 Episode : Fidished after 28 time steps\n",
      "36 Episode : Fidished after 36 time steps\n",
      "37 Episode : Fidished after 37 time steps\n",
      "38 Episode : Fidished after 52 time steps\n",
      "39 Episode : Fidished after 39 time steps\n",
      "40 Episode : Fidished after 13 time steps\n",
      "41 Episode : Fidished after 60 time steps\n",
      "42 Episode : Fidished after 56 time steps\n",
      "43 Episode : Fidished after 66 time steps\n",
      "44 Episode : Fidished after 63 time steps\n",
      "45 Episode : Fidished after 69 time steps\n",
      "46 Episode : Fidished after 20 time steps\n",
      "47 Episode : Fidished after 66 time steps\n",
      "48 Episode : Fidished after 73 time steps\n",
      "49 Episode : Fidished after 81 time steps\n",
      "50 Episode : Fidished after 64 time steps\n",
      "51 Episode : Fidished after 46 time steps\n",
      "52 Episode : Fidished after 27 time steps\n",
      "53 Episode : Fidished after 80 time steps\n",
      "54 Episode : Fidished after 16 time steps\n",
      "55 Episode : Fidished after 200 time steps\n",
      "56 Episode : Fidished after 74 time steps\n",
      "57 Episode : Fidished after 88 time steps\n",
      "58 Episode : Fidished after 69 time steps\n",
      "59 Episode : Fidished after 108 time steps\n",
      "60 Episode : Fidished after 96 time steps\n",
      "61 Episode : Fidished after 200 time steps\n",
      "62 Episode : Fidished after 185 time steps\n",
      "63 Episode : Fidished after 62 time steps\n",
      "64 Episode : Fidished after 14 time steps\n",
      "65 Episode : Fidished after 145 time steps\n",
      "66 Episode : Fidished after 34 time steps\n",
      "67 Episode : Fidished after 16 time steps\n",
      "68 Episode : Fidished after 142 time steps\n",
      "69 Episode : Fidished after 11 time steps\n",
      "70 Episode : Fidished after 63 time steps\n",
      "71 Episode : Fidished after 51 time steps\n",
      "72 Episode : Fidished after 10 time steps\n",
      "73 Episode : Fidished after 61 time steps\n",
      "74 Episode : Fidished after 16 time steps\n",
      "75 Episode : Fidished after 91 time steps\n",
      "76 Episode : Fidished after 23 time steps\n",
      "77 Episode : Fidished after 25 time steps\n",
      "78 Episode : Fidished after 150 time steps\n",
      "79 Episode : Fidished after 30 time steps\n",
      "80 Episode : Fidished after 34 time steps\n",
      "81 Episode : Fidished after 108 time steps\n",
      "82 Episode : Fidished after 38 time steps\n",
      "83 Episode : Fidished after 151 time steps\n",
      "84 Episode : Fidished after 57 time steps\n",
      "85 Episode : Fidished after 58 time steps\n",
      "86 Episode : Fidished after 48 time steps\n",
      "87 Episode : Fidished after 16 time steps\n",
      "88 Episode : Fidished after 84 time steps\n",
      "89 Episode : Fidished after 54 time steps\n",
      "90 Episode : Fidished after 21 time steps\n",
      "91 Episode : Fidished after 96 time steps\n",
      "92 Episode : Fidished after 53 time steps\n",
      "93 Episode : Fidished after 41 time steps\n",
      "94 Episode : Fidished after 91 time steps\n",
      "95 Episode : Fidished after 90 time steps\n",
      "96 Episode : Fidished after 84 time steps\n",
      "97 Episode : Fidished after 33 time steps\n",
      "98 Episode : Fidished after 106 time steps\n",
      "99 Episode : Fidished after 103 time steps\n",
      "100 Episode : Fidished after 52 time steps\n",
      "101 Episode : Fidished after 20 time steps\n",
      "102 Episode : Fidished after 69 time steps\n",
      "103 Episode : Fidished after 15 time steps\n",
      "104 Episode : Fidished after 66 time steps\n",
      "105 Episode : Fidished after 93 time steps\n",
      "106 Episode : Fidished after 111 time steps\n",
      "107 Episode : Fidished after 106 time steps\n",
      "108 Episode : Fidished after 116 time steps\n",
      "109 Episode : Fidished after 114 time steps\n",
      "110 Episode : Fidished after 126 time steps\n",
      "111 Episode : Fidished after 93 time steps\n",
      "112 Episode : Fidished after 83 time steps\n",
      "113 Episode : Fidished after 116 time steps\n",
      "114 Episode : Fidished after 115 time steps\n",
      "115 Episode : Fidished after 138 time steps\n",
      "116 Episode : Fidished after 81 time steps\n",
      "117 Episode : Fidished after 47 time steps\n",
      "118 Episode : Fidished after 48 time steps\n",
      "119 Episode : Fidished after 75 time steps\n",
      "120 Episode : Fidished after 49 time steps\n",
      "121 Episode : Fidished after 43 time steps\n",
      "122 Episode : Fidished after 89 time steps\n",
      "123 Episode : Fidished after 81 time steps\n",
      "124 Episode : Fidished after 38 time steps\n",
      "125 Episode : Fidished after 56 time steps\n",
      "126 Episode : Fidished after 118 time steps\n",
      "127 Episode : Fidished after 114 time steps\n",
      "128 Episode : Fidished after 78 time steps\n",
      "129 Episode : Fidished after 59 time steps\n",
      "130 Episode : Fidished after 178 time steps\n",
      "131 Episode : Fidished after 14 time steps\n",
      "132 Episode : Fidished after 63 time steps\n",
      "133 Episode : Fidished after 96 time steps\n",
      "134 Episode : Fidished after 87 time steps\n",
      "135 Episode : Fidished after 82 time steps\n",
      "136 Episode : Fidished after 63 time steps\n",
      "137 Episode : Fidished after 25 time steps\n",
      "138 Episode : Fidished after 47 time steps\n",
      "139 Episode : Fidished after 51 time steps\n",
      "140 Episode : Fidished after 91 time steps\n",
      "141 Episode : Fidished after 200 time steps\n",
      "142 Episode : Fidished after 83 time steps\n",
      "143 Episode : Fidished after 94 time steps\n",
      "144 Episode : Fidished after 77 time steps\n",
      "145 Episode : Fidished after 200 time steps\n",
      "146 Episode : Fidished after 200 time steps\n",
      "147 Episode : Fidished after 200 time steps\n",
      "148 Episode : Fidished after 200 time steps\n",
      "149 Episode : Fidished after 101 time steps\n",
      "150 Episode : Fidished after 200 time steps\n",
      "151 Episode : Fidished after 47 time steps\n",
      "152 Episode : Fidished after 200 time steps\n",
      "153 Episode : Fidished after 120 time steps\n",
      "154 Episode : Fidished after 200 time steps\n",
      "155 Episode : Fidished after 200 time steps\n",
      "156 Episode : Fidished after 200 time steps\n",
      "157 Episode : Fidished after 105 time steps\n",
      "158 Episode : Fidished after 200 time steps\n",
      "159 Episode : Fidished after 200 time steps\n",
      "160 Episode : Fidished after 173 time steps\n",
      "161 Episode : Fidished after 83 time steps\n",
      "162 Episode : Fidished after 200 time steps\n",
      "163 Episode : Fidished after 200 time steps\n",
      "164 Episode : Fidished after 200 time steps\n",
      "165 Episode : Fidished after 200 time steps\n",
      "166 Episode : Fidished after 200 time steps\n",
      "167 Episode : Fidished after 69 time steps\n",
      "168 Episode : Fidished after 80 time steps\n",
      "169 Episode : Fidished after 100 time steps\n",
      "170 Episode : Fidished after 139 time steps\n",
      "171 Episode : Fidished after 72 time steps\n",
      "172 Episode : Fidished after 97 time steps\n",
      "173 Episode : Fidished after 160 time steps\n",
      "174 Episode : Fidished after 200 time steps\n",
      "175 Episode : Fidished after 200 time steps\n",
      "176 Episode : Fidished after 134 time steps\n",
      "177 Episode : Fidished after 145 time steps\n",
      "178 Episode : Fidished after 153 time steps\n",
      "179 Episode : Fidished after 142 time steps\n",
      "180 Episode : Fidished after 200 time steps\n",
      "181 Episode : Fidished after 163 time steps\n",
      "182 Episode : Fidished after 173 time steps\n",
      "183 Episode : Fidished after 165 time steps\n",
      "184 Episode : Fidished after 200 time steps\n",
      "185 Episode : Fidished after 105 time steps\n",
      "186 Episode : Fidished after 188 time steps\n",
      "187 Episode : Fidished after 124 time steps\n",
      "188 Episode : Fidished after 200 time steps\n",
      "189 Episode : Fidished after 84 time steps\n",
      "190 Episode : Fidished after 99 time steps\n",
      "191 Episode : Fidished after 184 time steps\n",
      "192 Episode : Fidished after 200 time steps\n",
      "193 Episode : Fidished after 59 time steps\n",
      "194 Episode : Fidished after 69 time steps\n",
      "195 Episode : Fidished after 103 time steps\n",
      "196 Episode : Fidished after 95 time steps\n",
      "197 Episode : Fidished after 39 time steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198 Episode : Fidished after 88 time steps\n",
      "199 Episode : Fidished after 64 time steps\n",
      "200 Episode : Fidished after 106 time steps\n",
      "201 Episode : Fidished after 87 time steps\n",
      "202 Episode : Fidished after 116 time steps\n",
      "203 Episode : Fidished after 200 time steps\n",
      "204 Episode : Fidished after 143 time steps\n",
      "205 Episode : Fidished after 117 time steps\n",
      "206 Episode : Fidished after 90 time steps\n",
      "207 Episode : Fidished after 63 time steps\n",
      "208 Episode : Fidished after 184 time steps\n",
      "209 Episode : Fidished after 102 time steps\n",
      "210 Episode : Fidished after 98 time steps\n",
      "211 Episode : Fidished after 61 time steps\n",
      "212 Episode : Fidished after 45 time steps\n",
      "213 Episode : Fidished after 97 time steps\n",
      "214 Episode : Fidished after 116 time steps\n",
      "215 Episode : Fidished after 42 time steps\n",
      "216 Episode : Fidished after 67 time steps\n",
      "217 Episode : Fidished after 136 time steps\n",
      "218 Episode : Fidished after 37 time steps\n",
      "219 Episode : Fidished after 34 time steps\n",
      "220 Episode : Fidished after 131 time steps\n",
      "221 Episode : Fidished after 200 time steps\n",
      "222 Episode : Fidished after 111 time steps\n",
      "223 Episode : Fidished after 200 time steps\n",
      "224 Episode : Fidished after 174 time steps\n",
      "225 Episode : Fidished after 178 time steps\n",
      "226 Episode : Fidished after 106 time steps\n",
      "227 Episode : Fidished after 125 time steps\n",
      "228 Episode : Fidished after 110 time steps\n",
      "229 Episode : Fidished after 65 time steps\n",
      "230 Episode : Fidished after 89 time steps\n",
      "231 Episode : Fidished after 67 time steps\n",
      "232 Episode : Fidished after 161 time steps\n",
      "233 Episode : Fidished after 113 time steps\n",
      "234 Episode : Fidished after 80 time steps\n",
      "235 Episode : Fidished after 104 time steps\n",
      "236 Episode : Fidished after 74 time steps\n",
      "237 Episode : Fidished after 92 time steps\n",
      "238 Episode : Fidished after 105 time steps\n",
      "239 Episode : Fidished after 67 time steps\n",
      "240 Episode : Fidished after 127 time steps\n",
      "241 Episode : Fidished after 119 time steps\n",
      "242 Episode : Fidished after 151 time steps\n",
      "243 Episode : Fidished after 68 time steps\n",
      "244 Episode : Fidished after 200 time steps\n",
      "245 Episode : Fidished after 200 time steps\n",
      "246 Episode : Fidished after 200 time steps\n",
      "247 Episode : Fidished after 200 time steps\n",
      "248 Episode : Fidished after 200 time steps\n",
      "249 Episode : Fidished after 200 time steps\n",
      "250 Episode : Fidished after 200 time steps\n",
      "251 Episode : Fidished after 106 time steps\n",
      "252 Episode : Fidished after 200 time steps\n",
      "253 Episode : Fidished after 200 time steps\n",
      "254 Episode : Fidished after 200 time steps\n",
      "255 Episode : Fidished after 200 time steps\n",
      "256 Episode : Fidished after 200 time steps\n",
      "257 Episode : Fidished after 200 time steps\n",
      "258 Episode : Fidished after 200 time steps\n",
      "259 Episode : Fidished after 200 time steps\n",
      "260 Episode : Fidished after 200 time steps\n",
      "261 Episode : Fidished after 181 time steps\n",
      "262 Episode : Fidished after 200 time steps\n",
      "263 Episode : Fidished after 124 time steps\n",
      "264 Episode : Fidished after 137 time steps\n",
      "265 Episode : Fidished after 27 time steps\n",
      "266 Episode : Fidished after 112 time steps\n",
      "267 Episode : Fidished after 156 time steps\n",
      "268 Episode : Fidished after 22 time steps\n",
      "269 Episode : Fidished after 151 time steps\n",
      "270 Episode : Fidished after 126 time steps\n",
      "271 Episode : Fidished after 193 time steps\n",
      "272 Episode : Fidished after 200 time steps\n",
      "273 Episode : Fidished after 200 time steps\n",
      "274 Episode : Fidished after 200 time steps\n",
      "275 Episode : Fidished after 200 time steps\n",
      "276 Episode : Fidished after 200 time steps\n",
      "277 Episode : Fidished after 161 time steps\n",
      "278 Episode : Fidished after 200 time steps\n",
      "279 Episode : Fidished after 121 time steps\n",
      "280 Episode : Fidished after 180 time steps\n",
      "281 Episode : Fidished after 200 time steps\n",
      "282 Episode : Fidished after 200 time steps\n",
      "283 Episode : Fidished after 41 time steps\n",
      "284 Episode : Fidished after 76 time steps\n",
      "285 Episode : Fidished after 34 time steps\n",
      "286 Episode : Fidished after 200 time steps\n",
      "287 Episode : Fidished after 83 time steps\n",
      "288 Episode : Fidished after 200 time steps\n",
      "289 Episode : Fidished after 200 time steps\n",
      "290 Episode : Fidished after 200 time steps\n",
      "291 Episode : Fidished after 18 time steps\n",
      "292 Episode : Fidished after 146 time steps\n",
      "293 Episode : Fidished after 80 time steps\n",
      "294 Episode : Fidished after 199 time steps\n",
      "295 Episode : Fidished after 200 time steps\n",
      "296 Episode : Fidished after 200 time steps\n",
      "297 Episode : Fidished after 200 time steps\n",
      "298 Episode : Fidished after 37 time steps\n",
      "299 Episode : Fidished after 130 time steps\n",
      "300 Episode : Fidished after 200 time steps\n",
      "301 Episode : Fidished after 147 time steps\n",
      "302 Episode : Fidished after 200 time steps\n",
      "303 Episode : Fidished after 200 time steps\n",
      "304 Episode : Fidished after 200 time steps\n",
      "305 Episode : Fidished after 200 time steps\n",
      "306 Episode : Fidished after 169 time steps\n",
      "307 Episode : Fidished after 188 time steps\n",
      "308 Episode : Fidished after 168 time steps\n",
      "309 Episode : Fidished after 179 time steps\n",
      "310 Episode : Fidished after 200 time steps\n",
      "311 Episode : Fidished after 200 time steps\n",
      "312 Episode : Fidished after 200 time steps\n",
      "313 Episode : Fidished after 200 time steps\n",
      "314 Episode : Fidished after 120 time steps\n",
      "315 Episode : Fidished after 200 time steps\n",
      "316 Episode : Fidished after 141 time steps\n",
      "317 Episode : Fidished after 175 time steps\n",
      "318 Episode : Fidished after 125 time steps\n",
      "319 Episode : Fidished after 200 time steps\n",
      "320 Episode : Fidished after 200 time steps\n",
      "321 Episode : Fidished after 200 time steps\n",
      "322 Episode : Fidished after 200 time steps\n",
      "323 Episode : Fidished after 200 time steps\n",
      "324 Episode : Fidished after 200 time steps\n",
      "325 Episode : Fidished after 200 time steps\n",
      "326 Episode : Fidished after 150 time steps\n",
      "327 Episode : Fidished after 200 time steps\n",
      "328 Episode : Fidished after 34 time steps\n",
      "329 Episode : Fidished after 200 time steps\n",
      "330 Episode : Fidished after 18 time steps\n",
      "331 Episode : Fidished after 171 time steps\n",
      "332 Episode : Fidished after 200 time steps\n",
      "333 Episode : Fidished after 200 time steps\n",
      "334 Episode : Fidished after 200 time steps\n",
      "335 Episode : Fidished after 200 time steps\n",
      "336 Episode : Fidished after 200 time steps\n",
      "337 Episode : Fidished after 200 time steps\n",
      "338 Episode : Fidished after 200 time steps\n",
      "339 Episode : Fidished after 200 time steps\n",
      "340 Episode : Fidished after 200 time steps\n",
      "341 Episode : Fidished after 200 time steps\n",
      "10 episode 연속 성공\n",
      "342 Episode : Fidished after 200 time steps\n"
     ]
    }
   ],
   "source": [
    "cartpole_env = Environment()\n",
    "cartpole_env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
